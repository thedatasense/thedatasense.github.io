
\section{Multi-modal LLMs in Healthcare}
\subsection{Images}
Multi-modal LLMs promise significant potential for automating and improving clinical workflows. These models can integrate information from various image modalities such as X-rays, PET scans, MRIs, ultrasounds, and pathology slides. They could assist in tasks such as supporting diagnosis, summarizing clinical reports, and identifying similar clinical cases, ultimately improving decision making and efficiency in healthcare.

\subsubsection{Related Work }

\begin{tcolorbox}[title=Model: LLaVA-Med 1.5 \cite{li_llava-med_2023}, cardstyle]
\textbf{Architecture:}  
\begin{itemize}
    \item Vision encoder: CLIP ViT-L/336px extracts image features.
    \item Vision-language connector: MLP bridges visual and text modalities.
    \item Language model: Vicuna v1.5 13B processes and generates text outputs.
    \item Tokenizer converts text into embeddings for the language model.
    \item Modular design for seamless integration of vision and language tasks.
\end{itemize}

\textbf{Data:}
\begin{itemize}
    \item Novel data generation method using GPT-4 for self-instruction.
    \item Leverages biomedical image-text pairs from PubMed Central.
    \item Focuses on multimodal biomedical instruction-following tasks.
\end{itemize}

\textbf{Model and Data Availabilty:}
\begin{itemize}
\item Available at \href{https://github.com/microsoft/LLaVA-Med}{Github}
\end{itemize}
\textbf{Evaluation Method:}
\begin{itemize}
    \item Assessed on medical visual chat and VQA tasks (e.g., VQA-Radiology, SLAKE, Pathology-VQA).
    \item Compared against other fine-tuning and modeling approaches.
\end{itemize}

\textbf{Robustness, Safety and Bias:}
\begin{itemize}
    \item Not explicitly discussed in the context of this model.
    \item Contributions focus on data generation and modeling.
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[title=Model: Visual Med-Alpaca \cite{chen_vision-language_2024}, cardstyle]
\textbf{Architecture:}  
\begin{itemize}
    \item Bridges textual and visual modalities using prompt augmentation.
    \item Type classifier identifies the appropriate module for visual input processing.
    \item Visual experts (e.g., Med-GIT, DePlot) convert images into intermediate text representations.
    \item Text and visual inputs are merged to generate responses via the Med-Alpaca model.
    \item Based on the LLaMA-7B foundation model, fine-tuned with LoRA for biomedical tasks.
\end{itemize}

\textbf{Data:}
\begin{itemize}
    \item Biomedical instruction set generated using GPT-3.5-Turbo with human filtering.
    \item 54,000 high-quality question-answer pairs derived from BigBIO datasets.
    \item Visual modality incorporated using radiology image datasets (e.g., ROCO).
\end{itemize}

\textbf{Evaluation Method:}
\begin{itemize}
    \item Assessed on medical question-answering tasks and visual reasoning benchmarks.
    \item Includes diverse cases such as radiology image captioning and medical chat scenarios.
\end{itemize}

\textbf{Safety and Bias:}
\begin{itemize}
    \item Strictly for academic research; not approved for clinical or commercial use.
    \item Limitations include potential misinformation and lack of liability for accuracy.
\end{itemize}

\textbf{Data and Model Availability:}
\begin{itemize}
    \item Code and datasets are available on \href{https://cambridgeltl.github.io/visual-med-alpaca/}{GitHub} for academic use.
    \item Models include Med-Alpaca, Med-Alpaca-LoRA, and Med-GIT.
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[title=Model: CheXagent, cardstyle]
\textbf{Architecture:}
\begin{itemize}
    \item Consists of three core components:
        \begin{itemize}
            \item \textbf{Image Encoder}: SigLIP-Large transformer with 24 layers, adapted for CXR with a resolution of 512px.
            \item \textbf{Vision-Language Projector}: A two-layer MLP projecting visual features into the language decoder's feature space (1,024 to 2,560 dimensions).
            \item \textbf{Language Decoder}: Phi-2.7B, a 2.7B parameter transformer trained on medical, scientific, and general-domain text.
        \end{itemize}
    \item Processes input images and instructions to generate free-form text responses.
\end{itemize}

\textbf{Training:}
\begin{itemize}
    \item Language decoder trained on 2.7 billion tokens from clinical notes, scientific articles, Wikipedia-style text, and general-domain text.
    \item Image encoder trained using 1,052,257 image-text pairs derived from CheXinstruct.
    \item Combined training on CheXinstruct triplets (instruction, image, response) with the image encoder unfrozen for one epoch and frozen for three epochs.
    \item Loss function: causal language modeling (next-word prediction).
\end{itemize}

\textbf{Evaluation Method:}
\begin{itemize}
    \item Assessed on tasks such as report generation, abnormality detection, and image-text reasoning.
    \item Used separate validation sets from CheXinstruct to avoid data leakage.
\end{itemize}

\textbf{Data and Model Availability:}
\begin{itemize}
    \item Training datasets and splits follow official conventions to ensure reproducibility.
    \item Model details and hyperparameters are provided in supplementary materials.
\end{itemize}

\textbf{Safety and Bias:}
\begin{itemize}
    \item Strictly for academic research; not approved for clinical or commercial use.
    \item Limitations include risks of misinformation and biases in medical reasoning.
\end{itemize}
\end{tcolorbox}

\subsection{EHR/Temporal Data}

\begin{tcolorbox}[title=Model: GatorTron \cite{yang_large_2022}, cardstyle]
\textbf{Objective:}  
\begin{itemize}
    \item Develop a large-scale clinical language model to process and interpret unstructured electronic health records (EHRs).
    \item Explore the impact of scaling model parameters and training data on clinical NLP tasks.
\end{itemize}

\textbf{Architecture:}
\begin{itemize}
    \item Built from scratch as a large clinical language model.
    \item Scales from 110 million to 8.9 billion parameters for improved performance.
    \item Trained on >90 billion words of text, including >82 billion words of de-identified clinical text.
\end{itemize}

\textbf{Data:}
\begin{itemize}
    \item Includes a mix of de-identified clinical text and general domain text.
    \item Designed to tackle unstructured data from EHRs effectively.
\end{itemize}

\textbf{Evaluation Method:}
\begin{itemize}
    \item Systematically evaluated on five clinical NLP tasks:
    \begin{itemize}
        \item Clinical concept extraction.
        \item Medical relation extraction.
        \item Semantic textual similarity.
        \item Natural language inference (NLI).
        \item Medical question answering (MQA).
    \end{itemize}
\end{itemize}

\textbf{Key Findings:}
\begin{itemize}
    \item Scaling model size and training data enhances performance across clinical NLP tasks.
    \item Demonstrates potential for medical AI systems to utilize unstructured EHRs for improved healthcare delivery.
\end{itemize}

\textbf{Safety and Bias:}
\begin{itemize}
    \item Not approved for clinical or commercial use.
    \item Intended strictly for academic research.
\end{itemize}

\textbf{Data and Model Availability:}
\begin{itemize}
    \item GatorTron models are publicly available at \href{https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/gatortron_og}{NVIDIA NGC Catalog}.
\end{itemize}
\end{tcolorbox}

\begin{tcolorbox}[title=Model: Large Language Models as Few-Shot Health Learners \cite{liu_few_shot_2024}, cardstyle]
\textbf{Objective:}
\begin{itemize}
    \item Explore the capability of large language models (LLMs) to ground physiological and behavioral time-series data.
    \item Demonstrate meaningful inferences in clinical and wellness contexts with few-shot tuning.
\end{itemize}

\textbf{Architecture:}
\begin{itemize}
    \item Based on a 24 billion parameter transformer model (PaLM).
    \item Pretrained on a massive text corpus of 780 billion tokens, including filtered web pages, books, Wikipedia, news, social media, and code from GitHub.
    \item Significant language and reasoning capabilities, but not inherently dependable for physiological and behavioral data queries without fine-tuning.
\end{itemize}

\textbf{Applications:}
\begin{itemize}
    \item Cardiac signal analysis.
    \item Physical activity recognition.
    \item Metabolic calculations (e.g., calories burned).
    \item Estimation of stress reports and mental health screening scores.
\end{itemize}

\textbf{Methodology:}
\begin{itemize}
    \item Few-shot tuning using data from wearable and medical sensor recordings.
    \item Evaluation on health tasks requiring integration of physiological and behavioral data.
\end{itemize}

\textbf{Key Findings:}
\begin{itemize}
    \item LLMs can ground numerical data (e.g., vital signs, movement, and laboratory values) for health-related tasks.
    \item Show promise for bridging the gap between numerical data and text-based inferences in health applications.
\end{itemize}

\textbf{Safety and Bias:}
\begin{itemize}
    \item Not inherently dependable without domain-specific fine-tuning.
    \item Requires careful evaluation for clinical reliability and safety.
\end{itemize}
\end{tcolorbox}

\subsection{Audio}

\begin{landscape} % Begin landscape environment
\section{LLM Healthcare - Validation Datasets}

\begin{table}[ht]
\centering
\caption{Diagnostic Accuracy Datasets and Descriptions}
\begin{tabular}{|l|p{12cm}|}
\hline
\textbf{Dataset} & \textbf{Description} \\ \hline
\textbf{NEJM Clinicopathologic Conference Cases} & 
143 diagnostic cases (2021 to September 2024), including 70 cases previously evaluated with GPT-4. Differential diagnoses and testing plans were scored by attending physicians using the Bond Score (range: 0–5) and Likert scale (range: 0–2) respectively. Interrater agreement was assessed using linear-weighted Cohen’s kappa. Sensitivity analysis compared cases before and after October 2023 to assess memorization. \\ \hline

\textbf{NEJM Healer Diagnostic Cases} & 
20 cases divided into four sequential stages: triage presentation, review of systems, physical exam, and diagnostic tests. Prompts adapted from prior GPT-4 studies evaluated the quality of clinical reasoning using the R-IDEA score (10-point scale). “Cannot-miss” diagnoses were identified for the initial triage presentation data. Interrater agreement was computed, and historical controls included GPT-4, attending physicians, and resident physicians. \\ \hline

\textbf{Grey Matters Management Cases} & 
Five cases graded by attending physicians based on a 100-point rubric derived from prior studies. Performance compared to GPT-4, humans with GPT-4, and humans with non-LLM resources using a linear mixed-effects model. Historical controls included data from 176 physicians with GPT-4 and 199 physicians with conventional resources. \\ \hline

\textbf{Landmark Diagnostic Cases} & 
Six clinical vignettes adapted from a landmark study for evaluating diagnostic systems. Scored on initial diagnoses, supporting/opposing factors, final diagnosis, and next diagnostic steps (normalized to 100-point scale). Interrater agreement was computed, and performance was compared to GPT-4, humans with GPT-4, and humans with conventional resources. \\ \hline

\textbf{Diagnostic Probabilistic Reasoning Cases} & 
Five cases from a prior study testing probabilistic reasoning. Posed questions on how probabilities change with positive or negative test results. Predictions were evaluated using mean absolute error (MAE) and mean absolute percentage error compared to reference probabilities from literature. \\ \hline

\textbf{MIMIC-IV-Ext Clinical Decision Making (MIMIC-CDM)} & 
Curated dataset derived from the MIMIC-IV database containing de-identified electronic health records. Includes data from 2,400 unique patients presenting with acute abdominal pain to the emergency department, with primary diagnoses of appendicitis, cholecystitis, diverticulitis, or pancreatitis. These diagnoses account for 10\% of emergency department visits and are differentiable using standard diagnostic tests present in the dataset. Steps for creating the dataset are detailed in the Methods section and Figure 1a. \\ \hline
\end{tabular}
\label{tab:diagnostic_datasets}
\end{table}
\end{landscape} % End landscape environment


