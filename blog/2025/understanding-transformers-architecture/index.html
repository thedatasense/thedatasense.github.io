<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Understanding the Transformer Architecture: A Deep Dive | Binesh K Sadanandan </title> <meta name="author" content="Binesh K Sadanandan"> <meta name="description" content="Binesh Kumar, AI in Healthcare, Precision Oncology, Reinforcement Learning, Data Science. "> <meta name="keywords" content="binesh kumar, binesh, sadanandan, sail, university of new haven, medtronic"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://bineshkumar.me/#%20the%20base%20hostname%20&amp;%20protocol%20for%20your%20site/blog/2025/understanding-transformers-architecture/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Binesh K Sadanandan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Understanding the Transformer Architecture: A Deep Dive</h1> <p class="post-meta"> February 15, 2025 • Binesh K Sadanandan </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/transformers"> <i class="fa-solid fa-hashtag fa-sm"></i> transformers</a>   <a href="/blog/tag/attention-mechanism"> <i class="fa-solid fa-hashtag fa-sm"></i> attention-mechanism</a>   <a href="/blog/tag/neural-networks"> <i class="fa-solid fa-hashtag fa-sm"></i> neural-networks</a>   <a href="/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> nlp</a>     ·   <a href="/blog/category/research"> <i class="fa-solid fa-tag fa-sm"></i> research</a>   <a href="/blog/category/deep-learning"> <i class="fa-solid fa-tag fa-sm"></i> deep-learning</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Originally introduced in “Attention is All You Need” by Vaswani et al., the transformer architecture has revolutionized natural language processing and beyond. This post provides a comprehensive overview of the transformer architecture, its key components, and the attention mechanism that powers it.</p> <h2 id="high-level-overview">High-Level Overview</h2> <p>The transformer architecture consists of two main components:</p> <ul> <li> <strong>Encoder</strong>: Processes the input text and encodes it into contextual vectors</li> <li> <strong>Decoder</strong>: Takes these encoded vectors and generates the output text</li> </ul> <p>Both encoder and decoder use layers of self-attention mechanisms that allow the model to weigh and learn the importance of words in a sequence with respect to each other.</p> <h3 id="why-transformers">Why Transformers?</h3> <p>Unlike RNNs and LSTMs that process sequences one word/token at a time, transformers process entire sequences at once. This parallel processing capability offers several advantages:</p> <ul> <li>Eliminates sequential dependencies that hinder parallelization</li> <li>Better captures long-term dependencies in sequences</li> <li>Significantly improves training time</li> </ul> <h2 id="the-encoder">The Encoder</h2> <p>The encoder is a stack of multiple identical layers (6 in the original transformer paper). Each layer consists of:</p> <h3 id="1-multi-headed-self-attention">1. Multi-Headed Self-Attention</h3> <p>The encoder processes the input sequence using self-attention, where each token attends to every other token. This captures dependencies between words, regardless of their position in the sequence. Input tokens are represented as embeddings, added to positional encodings to retain order information.</p> <h3 id="2-add--norm-layers">2. Add &amp; Norm Layers</h3> <ul> <li> <strong>Add</strong>: A residual connection where the input to a sublayer is added back to its output</li> <li> <strong>Norm</strong>: Layer normalization that ensures consistent scale of inputs across layers</li> </ul> <p>These components help stabilize training by avoiding the vanishing gradient problem and allow the model to learn identity mappings when needed.</p> <h3 id="3-feedforward-neural-network">3. Feedforward Neural Network</h3> <p>A fully connected layer that processes the output of the attention mechanism to refine token representations.</p> <h3 id="4-residual-connections-and-layer-normalization">4. Residual Connections and Layer Normalization</h3> <p>These stabilize training by passing the input of each layer forward along with the processed output.</p> <h2 id="the-decoder">The Decoder</h2> <p>The decoder is also a stack of identical layers, but each layer has three key components:</p> <h3 id="1-masked-multi-headed-self-attention">1. Masked Multi-Headed Self-Attention</h3> <p>The decoder attends to its own previous outputs, but masking is applied to prevent attending to future tokens (maintaining causality during generation).</p> <h3 id="2-cross-attention">2. Cross-Attention</h3> <p>This is where the decoder attends to the encoder’s output representations. At each decoding step, the decoder uses:</p> <ul> <li>Encoder’s output as key-value pairs</li> <li>Its own hidden state as the query</li> </ul> <p>This allows the decoder to focus on relevant parts of the input sentence for the current output token.</p> <h3 id="3-feedforward-layer">3. Feedforward Layer</h3> <p>Like the encoder, a fully connected layer refines the decoder’s representations.</p> <h2 id="the-attention-mechanism">The Attention Mechanism</h2> <h3 id="key-components">Key Components</h3> <ul> <li> <strong>Input Embeddings</strong>: Words or tokens represented as vectors (e.g., [“we,” “train,” “a,” “transformer,” “model”])</li> <li> <strong>Trainable Weight Matrices</strong>: <ul> <li>\(W_X\): Transforms inputs into query vectors (\(Q\))</li> <li>\(W_Y\): Transforms inputs into key vectors (\(K\))</li> <li>\(W_Z\): Transforms inputs into value vectors (\(V\))</li> </ul> </li> </ul> <h3 id="steps-in-self-attention">Steps in Self-Attention</h3> <ol> <li> <p><strong>Compute Q, K, and V</strong>: Multiply the input matrix \(X\) by weight matrices \(W_X\), \(W_Y\), and \(W_Z\). Each token \(x_i\) is associated with:</p> <ul> <li>\(q_i\): Seeks relevant information</li> <li>\(k_i\): Provides relevance clues</li> <li>\(v_i\): Contains semantic information</li> </ul> </li> <li> <p><strong>Compute Attention Scores</strong>: For token \(x_i\), calculate \(q_i \cdot k_j\) (dot product) for all \(j\). This measures the similarity between \(q_i\) and \(k_j\).</p> </li> <li> <p><strong>Scale the Scores</strong>: Divide each score by \(\sqrt{d_k}\), where \(d_k\) is the dimensionality of the key vectors. This prevents large values from destabilizing the softmax function.</p> </li> <li> <p><strong>Apply Causal Mask</strong>: Add a mask to ensure tokens only attend to current and previous tokens (not future ones). Example for position 2: \(\text{causal\_mask} = [0, 0, -\infty, -\infty]\)</p> </li> <li> <p><strong>Apply Softmax</strong>: Convert masked scores into probabilities (attention weights): \(\text{softmax}(\text{masked\_scores}) \rightarrow [w_1, w_2, \ldots, w_n]\)</p> </li> <li> <p><strong>Weighted Sum of Value Vectors</strong>: Use attention weights to compute the output for each token: \(g_i = \sum_{j=1}^{n} w_j \cdot v_j\)</p> </li> </ol> <h3 id="the-key-formula">The Key Formula</h3> <p>The attention mechanism for all tokens can be expressed as:</p> \[G = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}} + M\right) V\] <p>Where:</p> <ul> <li>\(Q, K, V\): Query, key, and value matrices</li> <li>\(M\): Causal mask</li> </ul> <h2 id="byte-pair-encoding-bpe">Byte Pair Encoding (BPE)</h2> <p>Byte Pair Encoding is a subword tokenization algorithm widely used in transformer models like GPT. It balances the trade-off between vocabulary size and the ability to represent rare and unseen words.</p> <h3 id="why-bpe">Why BPE?</h3> <p>Traditional tokenization algorithms in NLP:</p> <ul> <li>Lack computational efficiency</li> <li>Fail to represent unseen words effectively</li> </ul> <p>BPE addresses these issues by breaking text into subwords and learning a vocabulary of frequent subword patterns.</p> <h3 id="the-bpe-algorithm">The BPE Algorithm</h3> <ol> <li> <strong>Initialization</strong>: Start with a vocabulary of individual characters and a special end-of-word symbol (e.g., <code class="language-plaintext highlighter-rouge">_</code>)</li> <li> <strong>Tokenization</strong>: Represent the input text as a sequence of these initial tokens</li> <li> <strong>Merge Operations</strong>: Iteratively merge the most frequent adjacent token pairs into a new token. Each merge: <ul> <li>Reduces the sequence length</li> <li>Adds the merged token to the vocabulary</li> </ul> </li> <li> <strong>Stopping Criterion</strong>: Stop after a predefined number of merges or when no frequent pairs remain</li> </ol> <h2 id="conclusion">Conclusion</h2> <p>The transformer architecture’s innovative use of attention mechanisms has made it the foundation of modern NLP systems. By processing sequences in parallel and effectively capturing long-range dependencies, transformers have enabled breakthrough models like BERT, GPT, and many others that continue to push the boundaries of what’s possible in AI.</p> <h2 id="references">References</h2> <p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … &amp; Polosukhin, I. (2017). Attention is all you need. <em>Advances in neural information processing systems</em>, 30.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/large-language-models-comprehensive-guide/">Large Language Models: From Architecture to Evaluation</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/adversarial-robustness-vision-language-models/">The Evolution of Adversarial Robustness: From Neural Networks to Vision-Language Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/multimodal-llms-healthcare-applications/">Multimodal Large Language Models in Healthcare: Current Applications and Validation Approaches</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/mllmguard-safety-framework/">MLLMGuard: A Comprehensive Safety Framework for Multimodal Large Language Models</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Binesh K Sadanandan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>